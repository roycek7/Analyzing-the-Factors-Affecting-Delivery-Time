{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Remove-all-rows-with-missing-values-in-order-delivered_carrier_date-or-order_delivered_customer_date\" data-toc-modified-id=\"Remove-all-rows-with-missing-values-in-order-delivered_carrier_date-or-order_delivered_customer_date-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Remove all rows with missing values in order delivered_carrier_date or order_delivered_customer_date</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Outliers and Time Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(df=None):\n",
    "    if df is not None:\n",
    "        df = time_format(df)\n",
    "        df = create_order_session(create_order_weekday(df))\n",
    "        df = remove_empty_rows(create_metric_dimension_product(df))\n",
    "        df = remove_geolocation_outliers(df)\n",
    "        return df\n",
    "\n",
    "def create_order_weekday(df=None):\n",
    "    if df is None:\n",
    "        return\n",
    "    df['order_purchase_weekday'] = df['order_purchase_timestamp'].dt.day_name()\n",
    "    df = df.assign(order_purchase_session=pd.cut(df.order_purchase_timestamp.dt.hour, [0, 6, 12, 18, 24],\n",
    "                                                 labels=['Night', 'Morning', 'Afternoon', 'Evening'], right=False))\n",
    "    return df\n",
    "\n",
    "def create_order_session(df=None):\n",
    "    if df is None:\n",
    "        return\n",
    "    winter = [12, 1, 2]\n",
    "    spring = [3, 4, 5]\n",
    "    summer = [6, 7, 8]\n",
    "    autumn = [9, 10, 11]\n",
    "    d = {**dict.fromkeys(winter, 'winter'), **dict.fromkeys(spring, 'spring'), **dict.fromkeys(summer, 'summer'),\n",
    "         **dict.fromkeys(autumn, 'autumn')}\n",
    "\n",
    "    df['season'] = list(map(d.get, df.order_purchase_timestamp.dt.month))\n",
    "    return df\n",
    "\n",
    "def create_metric_dimension_product(df=None):\n",
    "    if df is not None:\n",
    "        df['product_weight_kg'], df['product_weight_g'] = df['product_weight_g'] // 1000, \\\n",
    "                                                          df['product_weight_g'] % 1000\n",
    "        df['product_length_m'], df['product_length_cm'] = df['product_length_cm'] // 100, \\\n",
    "                                                          df['product_length_cm'] % 100\n",
    "        df['product_height_m'], df['product_height_cm'] = df['product_height_cm'] // 100, \\\n",
    "                                                          df['product_height_cm'] % 100\n",
    "        df['product_width_m'], df['product_width_cm'] = df['product_width_cm'] // 100, \\\n",
    "                                                        df['product_width_cm'] % 100\n",
    "    return df\n",
    "\n",
    "def remove_empty_rows(df=None):\n",
    "    if df is None:\n",
    "        return\n",
    "    df = df[df['product_category_name_english'].notna()]\n",
    "    return df\n",
    "\n",
    "\n",
    "def time_format(data):\n",
    "    '''\n",
    "    Function to convert dataset time columns into pandas datetime and calculations for promise date,\n",
    "    approval time and total time to deliver\n",
    "    '''\n",
    "    data.order_purchase_timestamp = pd.to_datetime(data.order_purchase_timestamp, format='%d/%m/%Y %H:%M')\n",
    "    data.order_approved_at = pd.to_datetime(data.order_approved_at, errors='coerce', format='%d/%m/%Y %H:%M')\n",
    "    data.order_estimated_delivery_date = pd.to_datetime(data.order_estimated_delivery_date, errors='coerce', format='%d/%m/%Y %H:%M')\n",
    "    data.order_delivered_customer_date = pd.to_datetime(data.order_delivered_customer_date, errors='coerce', format='%d/%m/%Y %H:%M')\n",
    "    df.order_delivered_carrier_date = pd.to_datetime(df.order_delivered_carrier_date, errors='coerce', format='%d/%m/%Y %H:%M')\n",
    "    data['promise_date'] = data.order_estimated_delivery_date >= data.order_delivered_customer_date  # True if product delivered before or at estimated delivery date\n",
    "    data['approval_time'] = data.order_approved_at - data.order_purchase_timestamp  # Time for buyer to approve sale\n",
    "    #data['total_time_to_deliver'] = data.order_delivered_customer_date - data.order_purchase_timestamp  # total time from pruchase to delivery\n",
    "    #data['actual_delivery_time'] = data.order_delivered_customer_date - data.order_delivered_carrier_date  # total time from pruchase to delivery\n",
    "    data['actual_delivery_time'] = ((pd.to_datetime(df['order_delivered_customer_date']) - \n",
    "                            pd.to_datetime(df['order_delivered_carrier_date']))\n",
    "                                .dt.total_seconds() / (60 * 60))\n",
    "    data['total_delivery_time'] = ((pd.to_datetime(df['order_delivered_customer_date']) - \n",
    "                            pd.to_datetime(df['order_purchase_timestamp']))\n",
    "                                .dt.total_seconds() / (60 * 60))\n",
    "\n",
    "    return data\n",
    "\n",
    "def remove_geolocation_outliers(data):\n",
    "    # Removing some outliers \n",
    "    #Brazils most Northern spot is at 5 deg 16′ 27.8″ N latitude.;\n",
    "    data = data[data.geolocation_lat <= 5.27438888]\n",
    "    #it's most Western spot is at 73 deg, 58′ 58.19″W Long.\n",
    "    data = data[data.geolocation_lng >= -73.98283055]\n",
    "    #It's most southern spot is at 33 deg, 45′ 04.21″ S Latitude.\n",
    "    data = data[data.geolocation_lat >= -33.75116944]\n",
    "    #It's most Eastern spot is 34 deg, 47′ 35.33″ W Long.\n",
    "    data = data[data.geolocation_lng <=  -34.79314722]\n",
    "    return data\n",
    "\n",
    "def null_dates(data):\n",
    "    '''\n",
    "    Function to find indexes of order's with null times, most of these rows are order_delievered_customer_date.\n",
    "    This is probably due to cancelations\n",
    "    '''\n",
    "    na = data[['order_purchase_timestamp', 'order_approved_at', 'order_estimated_delivery_date',\n",
    "               'order_delivered_customer_date']][data[\n",
    "        ['order_purchase_timestamp', 'order_approved_at', 'order_estimated_delivery_date',\n",
    "         'order_delivered_customer_date']].isna().any(1)].index\n",
    "\n",
    "    return na\n",
    "\n",
    "df = pd.read_csv('../../data/interim/consolidated_ecommerce_olist_1_sample.csv' , dtype={'seller_zip_code_prefix': str, 'customer_zip_code_prefix': str})\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_order_hour_and_date(df=None):\n",
    "    df['order_purchase_hour'] = df.order_purchase_timestamp.dt.hour\n",
    "    df['order_purchase_date'] = df.order_purchase_timestamp.dt.date\n",
    "    df['product_volumetric_weight'] = (df.product_weight_kg + df.product_weight_g )* (df.product_height_m + df.product_height_cm) * (df.product_width_m + df.product_width_cm)\n",
    "    return df\n",
    "\n",
    "df = create_order_hour_and_date(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all rows with missing values in order delivered_carrier_date or order_delivered_customer_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['order_delivered_carrier_date'].isnull() == False) & (df['order_delivered_customer_date'].isnull() == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = pd.read_csv('../../data/processed/processed_olist_geolocation_dataset.csv', dtype={'geolocation_zip_code_prefix': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.geolocation_zip_code_prefix = df_geo.geolocation_zip_code_prefix.apply(lambda x: '0' + x if(len(x) == 4) else x)\n",
    "df['seller_zip_code_prefix'] = df['seller_zip_code_prefix'].apply(lambda x: '0' + x if(len(x) == 4) else x)\n",
    "df['customer_zip_code_prefix'] = df['customer_zip_code_prefix'].apply(lambda x: '0' + x if(len(x) == 4) else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skyway Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "def compute_distance(row):\n",
    "    # Source: https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    customer = row.customer_zip_code_prefix\n",
    "    seller = row.seller_zip_code_prefix\n",
    "    seller_location = df_geo[df_geo.geolocation_zip_code_prefix == seller]\n",
    "    customer_location = df_geo[df_geo.geolocation_zip_code_prefix == customer]\n",
    "    if (seller_location.shape[0] == 0) or (customer_location.shape[0] == 0):\n",
    "        return None\n",
    "\n",
    "    lat_seller = radians(seller_location.geolocation_lat.iloc[0])\n",
    "    lng_seller = radians(seller_location.geolocation_lng.iloc[0])\n",
    "    \n",
    "    lat_customer = radians(customer_location.geolocation_lat.iloc[0])\n",
    "    lng_customer = radians(customer_location.geolocation_lng.iloc[0])\n",
    "    dlon = lng_seller - lng_customer\n",
    "    dlat = lat_seller - lat_customer\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat_seller) * cos(lat_customer) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance'] = df[['customer_zip_code_prefix', 'seller_zip_code_prefix']].apply(compute_distance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_order_hour_and_date(df=None):\n",
    "    df['order_purchase_hour'] = df.order_purchase_timestamp.dt.hour\n",
    "    df['order_purchase_date'] = df.order_purchase_timestamp.dt.date\n",
    "    df['product_area'] = ((df.product_height_m * 100) + df.product_height_cm) * ((df.product_width_m * 100) + df.product_width_cm)\n",
    "    df['product_volume'] = ((df.product_height_m * 100) + df.product_height_cm) * ((df.product_width_m * 100) + df.product_width_cm) * ((df.product_length_m * 100) + df.product_length_cm)\n",
    "    return df\n",
    "\n",
    "df = create_order_hour_and_date(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "#### Remove all rows with missing values in order delivered_carrier_date or order_delivered_customer_date\n",
    "df = df[(df['order_delivered_carrier_date'].isnull() == False) & (df['order_delivered_customer_date'].isnull() == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Category Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# orders having more than 1 items:  375\n",
      "# orders having more than 1 items BUT only have 1 product category:  173\n"
     ]
    }
   ],
   "source": [
    "idx = df['order_id'].value_counts()[df['order_id'].value_counts() > 1].index\n",
    "# Data contains orders with multiple items\n",
    "df_multiple_product_cat_order = df[df.order_id.isin(idx)]\n",
    "# Data contains orders with single item\n",
    "df_single_product_cat_order = df[~df.order_id.isin(idx)]\n",
    "\n",
    "# Filter all orders with multiple items but only have single product category\n",
    "only_1_product_cat = []\n",
    "for id in idx:\n",
    "    if len(df_multiple_product_cat_order[df_multiple_product_cat_order.order_id == id].product_category_name_english.unique()) == 1:\n",
    "        only_1_product_cat.append(id)\n",
    "        \n",
    "print('# orders having more than 1 items: ', len(df_multiple_product_cat_order))\n",
    "print('# orders having more than 1 items BUT only have 1 product category: ', len(only_1_product_cat))\n",
    "\n",
    "df_single_product_cat_multiple_item_order = df_multiple_product_cat_order[df_multiple_product_cat_order.order_id.isin(only_1_product_cat)]\n",
    "df_single_product_cat = df_single_product_cat_order.append(df_single_product_cat_multiple_item_order)\n",
    "\n",
    "df_grp_product_cat = df_single_product_cat.groupby('product_category_name_english').mean().reset_index().sort_values(by='total_delivery_time', ascending=True)\n",
    "\n",
    "# Encode product categories into numerical values\n",
    "df_grp_product_cat['encode_product_cat'] = np.linspace(1, df_grp_product_cat.shape[0], df_grp_product_cat.shape[0])\n",
    "df_grp_product_cat = df_grp_product_cat[['product_category_name_english', 'encode_product_cat']]\n",
    "df_grp_product_cat = df_grp_product_cat.set_index('product_category_name_english')\n",
    "df_grp_product_cat = df_grp_product_cat.to_dict()\n",
    "\n",
    "\n",
    "df_multiple_product_cat = df_multiple_product_cat_order[~df_multiple_product_cat_order.isin(df_single_product_cat_multiple_item_order).all(1)]\n",
    "\n",
    "imputed_product_cat_for_order = {}\n",
    "for id in df_multiple_product_cat.order_id.unique():\n",
    "    df_order = df_multiple_product_cat[df_multiple_product_cat.order_id == id]\n",
    "    unique_product_cat = df_order.product_category_name_english.unique()\n",
    "    max_product_cat = unique_product_cat[0]\n",
    "    for i in range(1, len(unique_product_cat)):\n",
    "        if df_grp_product_cat['encode_product_cat'][max_product_cat] < df_grp_product_cat['encode_product_cat'][unique_product_cat[i]]:\n",
    "            max_product_cat = unique_product_cat[i]\n",
    "    imputed_product_cat_for_order[df_order.order_id.iloc[0]] = max_product_cat\n",
    "    \n",
    "df['product_category_name_english'] = df['order_id'].map(lambda x: imputed_product_cat_for_order[x] if x in imputed_product_cat_for_order \\\n",
    "                                                         else df[df.order_id == x].product_category_name_english.iloc[0])\n",
    "\n",
    "\n",
    "idx = df['order_id'].value_counts()[df['order_id'].value_counts() > 1].index\n",
    "\n",
    "double_check_df = df[df['order_id'].isin(idx)]\n",
    "\n",
    "# Filter all orders with multiple items but only have single product category\n",
    "only_1_product_cat = []\n",
    "for id in idx:\n",
    "    if len(double_check_df[double_check_df.order_id == id].product_category_name_english.unique()) > 1:\n",
    "        only_1_product_cat.append(id)\n",
    "\n",
    "max_column = ['distance', 'order_item_id', 'review_id']\n",
    "mean_column = ['review_score']\n",
    "sum_column = ['freight_value', 'product_weight_kg', 'product_weight_g', 'product_width_cm', \\\n",
    "              'product_width_m', 'product_length_m', 'product_length_cm', \\\n",
    "              'product_height_m', 'product_height_cm', \\\n",
    "              'price', 'payment_value', 'payment_installments', \\\n",
    "              'product_volume', 'product_area']\n",
    "\n",
    "agg_dict = {}\n",
    "for col in df.columns:\n",
    "    if col in max_column:\n",
    "        agg_dict[col] = 'max'\n",
    "    elif col in mean_column:\n",
    "        agg_dict[col] = 'mean'\n",
    "    elif col in sum_column:\n",
    "        agg_dict[col] = 'sum'\n",
    "    else:\n",
    "        agg_dict[col] = 'unique'\n",
    "        \n",
    "df = df.groupby('order_id', sort=False).agg(agg_dict)\n",
    "\n",
    "for col in df.columns:\n",
    "    if (col not in max_column) or (col not in mean_column) or (col not in sum_column):\n",
    "        if isinstance(df[col].iloc[0], np.ndarray):\n",
    "            df[col] = df[col].apply(lambda x: x[0])\n",
    "            \n",
    "df.order_purchase_session = df.order_purchase_session.apply(lambda x: x[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Season For Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_season(df=None):\n",
    "    if df is None:\n",
    "        return\n",
    "    df['order_purchase_timestamp'] =  pd.to_datetime(df['order_purchase_timestamp'], format='%Y/%m/%d %H:%M:%S')\n",
    "    dry = [9, 10, 11, 12, 1, 2]\n",
    "    wet = [3, 4, 5, 6, 7, 8]\n",
    "    d = {**dict.fromkeys(dry, 'dry'), **dict.fromkeys(wet, 'wet')}\n",
    "    df['seasons'] = list(map(d.get, df.order_purchase_timestamp.dt.month))\n",
    "    return df\n",
    "\n",
    "df = create_season(df)\n",
    "\n",
    "df.seasons = df.seasons.astype('category')\n",
    "df.payment_type = df.payment_type.astype('category')\n",
    "\n",
    "# Remove all orders with invalid delivery time\n",
    "df = df[df.total_delivery_time > df.actual_delivery_time]\n",
    "df = df[df.actual_delivery_time > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection between Cities & States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_difference_in_hour(data, col1, col2, target_col):\n",
    "    data[target_col] = ((pd.to_datetime(data[col1]) - \n",
    "                            pd.to_datetime(data[col2]))\n",
    "                                .dt.total_seconds() / (60 * 60))\n",
    "    return\n",
    "\n",
    "def encode_categorical_variable_by_delivery_time(data, target_col_name, asc=True, rev=False):\n",
    "    df_cat_to_val = data.groupby(target_col_name).mean().reset_index().sort_values(by='total_delivery_time', ascending=asc)\n",
    "    # Encode categorical val into numerical val\n",
    "    encode_col_name = 'encode_' + target_col_name\n",
    "    if rev:\n",
    "        df_cat_to_val[encode_col_name] = np.linspace(1, df_cat_to_val.shape[0], df_cat_to_val.shape[0])\n",
    "    else:\n",
    "        df_cat_to_val[encode_col_name] = np.linspace(df_cat_to_val.shape[0], 1, df_cat_to_val.shape[0])\n",
    "    df_cat_to_val = df_cat_to_val[[target_col_name, encode_col_name]]\n",
    "    df_cat_to_val = df_cat_to_val.set_index(target_col_name)\n",
    "    df_cat_to_val = df_cat_to_val.to_dict()\n",
    "    # Map encoded vals into dataset\n",
    "    new_target_col_name = target_col_name + '_encoded'\n",
    "    data[new_target_col_name] = data[target_col_name].map(lambda x: df_cat_to_val[encode_col_name][x])\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "df['total_delivery_time_log'] = np.log(df['total_delivery_time'])\n",
    "df['actual_delivery_time_log'] = np.log(df['actual_delivery_time'])\n",
    "df['product_weight'] = (df['product_weight_kg'] * 1000) + df['product_weight_g']\n",
    "calculate_time_difference_in_hour(df, 'shipping_limit_date', 'order_purchase_timestamp', 'lag_time')\n",
    "calculate_time_difference_in_hour(df, 'order_delivered_carrier_date', 'order_purchase_timestamp', 'lag_time')\n",
    "encode_categorical_variable_by_delivery_time(df, 'product_category_name_english', asc=True, rev=False)\n",
    "\n",
    "df_states = df.groupby(['customer_state', 'seller_state']).mean()\n",
    "df_states = df_states['total_delivery_time'].reset_index()\n",
    "\n",
    "df_state_connection_grp = df.groupby(['customer_state', 'seller_state']).mean().sort_values(by='total_delivery_time', ascending=True).reset_index()\n",
    "\n",
    "# Encode pair of customer state & seller state into numeric value\n",
    "df_state_connection_grp['connection_between_states'] = np.linspace(df_state_connection_grp.shape[0], 1, df_state_connection_grp.shape[0])\n",
    "df_state_connection_grp = df_state_connection_grp[['customer_state', 'seller_state', 'connection_between_states']]\n",
    "df_state_connection_grp = df_state_connection_grp.set_index(['customer_state', 'seller_state'])\n",
    "df_state_connection_grp = df_state_connection_grp.to_dict()\n",
    "\n",
    "# Map each pair of customer state & seller state to the corresponding numerical value in dataset\n",
    "df['connection_between_states'] = df.apply(lambda x: df_state_connection_grp['connection_between_states'][(x.customer_state, x.seller_state)], axis=1)\n",
    "\n",
    "\n",
    "df_city_connection_grp = df.groupby(['customer_city', 'seller_city']).mean().sort_values(by=['total_delivery_time'], ascending=True).reset_index()\n",
    "\n",
    "# Encode pair of customer state & seller state into numeric value\n",
    "df_city_connection_grp['connection_between_cities'] = np.linspace(df_city_connection_grp.shape[0], 1, df_city_connection_grp.shape[0])\n",
    "df_city_connection_grp = df_city_connection_grp[['customer_city', 'seller_city', 'connection_between_cities']]\n",
    "df_city_connection_grp = df_city_connection_grp.set_index(['customer_city', 'seller_city'])\n",
    "df_city_connection_grp = df_city_connection_grp.to_dict()\n",
    "\n",
    "# Map each pair of customer state & seller state to the corresponding numerical value in dataset\n",
    "df['connection_between_cities'] = df.apply(lambda x: df_city_connection_grp['connection_between_cities'][(x.customer_city, x.seller_city)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('order_id', inplace=True)\n",
    "\n",
    "rdpc_df = pd.read_csv('../features/rdpc_features.csv')\n",
    "df = pd.merge(df, rdpc_df, on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zip_2_prefix_cat'] = df['zip_2_prefix'] = df.zip_2_prefix.astype('category').cat.codes\n",
    "\n",
    "df.rename(columns={'review_score_x': 'review_score', 'distance_x': 'distance', 'seasons_x': 'seasons', 'lag_time_x': 'lag_time', \n",
    "                  'connection_between_states_x': 'connection_between_states','connection_between_cities_x': 'connection_between_cities',\n",
    "                  'total_delivery_time_x': 'total_delivery_time'}, inplace=True)\n",
    "\n",
    "del df['total_delivery_time_y']\n",
    "\n",
    "df['connection_between_states'] = df['connection_between_states'].astype('int64')\n",
    "\n",
    "df['connection_between_cities'] = df['connection_between_cities'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seller Historical Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide = 'ignore')\n",
    "\n",
    "\n",
    "# df = df.sort_values(by=['order_purchase_timestamp'])\n",
    "seller_delivery = df.groupby(['customer_city','seller_city','seller_id','order_purchase_timestamp'],as_index=False)[['total_delivery_time']].agg(['count','sum'])\n",
    "seller_delivery.columns = [' '.join(col) for col in seller_delivery.columns]\n",
    "seller_delivery.reset_index(inplace=True)\n",
    "\n",
    "seller_delivery['total_delivery_time_CumSum'] = seller_delivery.groupby(['customer_city','seller_city','seller_id'])[['total_delivery_time sum']].cumsum()\n",
    "seller_delivery['total_delivery_time_CumCount'] = seller_delivery.groupby(['customer_city','seller_city','seller_id'])[['total_delivery_time count']].cumsum()\n",
    "seller_delivery['total_delivery_time_CumMean'] = seller_delivery['total_delivery_time_CumSum'] / seller_delivery['total_delivery_time_CumCount']\n",
    "seller_delivery['seller_delivery_PrevMean'] = seller_delivery.groupby(['customer_city','seller_city','seller_id'])['total_delivery_time_CumMean'].shift(0)\n",
    "\n",
    "df = df.merge(seller_delivery[['customer_city','seller_city','seller_id','order_purchase_timestamp','seller_delivery_PrevMean']],how='left',on=['customer_city','seller_city','seller_id','order_purchase_timestamp'])\n",
    "\n",
    "def FillNone(x):\n",
    "    if np.isnan(x['seller_delivery_PrevMean']):\n",
    "        return x['total_delivery_time']\n",
    "    else:\n",
    "        return x['seller_delivery_PrevMean']\n",
    "    \n",
    "df['seller_delivery_PrevMean']=df.apply(lambda x : FillNone(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/processed/20th_May_olist.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
